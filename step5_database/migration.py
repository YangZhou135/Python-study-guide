#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è¿ç§»è„šæœ¬
ä»æ–‡ä»¶å­˜å‚¨è¿ç§»åˆ°æ•°æ®åº“å­˜å‚¨
"""

import os
import sys
import json
import argparse
from datetime import datetime
from database import create_app
from models import db, User, Article, Tag, Comment

class DataMigrator:
    """æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self, app):
        self.app = app
        self.stats = {
            'users': {'migrated': 0, 'skipped': 0, 'errors': 0},
            'articles': {'migrated': 0, 'skipped': 0, 'errors': 0},
            'tags': {'migrated': 0, 'skipped': 0, 'errors': 0},
            'comments': {'migrated': 0, 'skipped': 0, 'errors': 0}
        }
    
    def migrate_from_files(self, source_dir='../step4_web/data'):
        """ä»æ–‡ä»¶å­˜å‚¨è¿ç§»æ•°æ®"""
        print("ğŸš€ å¼€å§‹ä»æ–‡ä»¶å­˜å‚¨è¿ç§»æ•°æ®...")
        
        with self.app.app_context():
            # æ¸…ç©ºç°æœ‰æ•°æ®
            if self._confirm_clear_database():
                self._clear_database()
            
            # è¿ç§»ç”¨æˆ·æ•°æ®
            self._migrate_users(source_dir)
            
            # è¿ç§»æ–‡ç« æ•°æ®
            self._migrate_articles(source_dir)
            
            # æ‰“å°è¿ç§»ç»Ÿè®¡
            self._print_migration_stats()
    
    def _confirm_clear_database(self):
        """ç¡®è®¤æ¸…ç©ºæ•°æ®åº“"""
        response = input("âš ï¸  æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®åº“æ•°æ®? (y/N): ")
        return response.lower() in ['y', 'yes']
    
    def _clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“"""
        print("ğŸ§¹ æ¸…ç©ºç°æœ‰æ•°æ®...")
        Comment.query.delete()
        Article.query.delete()
        Tag.query.delete()
        User.query.delete()
        db.session.commit()
        print("âœ… æ•°æ®åº“å·²æ¸…ç©º")
    
    def _migrate_users(self, source_dir):
        """è¿ç§»ç”¨æˆ·æ•°æ®"""
        users_file = os.path.join(source_dir, 'web_users.json')
        if not os.path.exists(users_file):
            print(f"âš ï¸  ç”¨æˆ·æ–‡ä»¶ä¸å­˜åœ¨: {users_file}")
            return
        
        print("ğŸ“¥ è¿ç§»ç”¨æˆ·æ•°æ®...")
        
        try:
            with open(users_file, 'r', encoding='utf-8') as f:
                users_data = json.load(f)
            
            for user_data in users_data:
                try:
                    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
                    existing_user = User.query.filter_by(username=user_data['username']).first()
                    if existing_user:
                        self.stats['users']['skipped'] += 1
                        continue
                    
                    # åˆ›å»ºæ–°ç”¨æˆ·
                    user = User(
                        username=user_data['username'],
                        email=user_data['email']
                    )
                    
                    # è®¾ç½®å¯†ç å“ˆå¸Œ
                    user.password_hash = user_data.get('password_hash', '')
                    
                    # è®¾ç½®å…¶ä»–å±æ€§
                    if 'created_at' in user_data:
                        user.created_at = datetime.fromisoformat(user_data['created_at'])
                    if 'last_login' in user_data and user_data['last_login']:
                        user.last_login = datetime.fromisoformat(user_data['last_login'])
                    if 'login_count' in user_data:
                        user.login_count = user_data['login_count']
                    
                    db.session.add(user)
                    self.stats['users']['migrated'] += 1
                    
                except Exception as e:
                    print(f"âŒ è¿ç§»ç”¨æˆ·å¤±è´¥ {user_data.get('username', 'Unknown')}: {e}")
                    self.stats['users']['errors'] += 1
            
            db.session.commit()
            print(f"âœ… ç”¨æˆ·è¿ç§»å®Œæˆ: {self.stats['users']['migrated']} ä¸ª")
            
        except Exception as e:
            print(f"âŒ è¯»å–ç”¨æˆ·æ–‡ä»¶å¤±è´¥: {e}")
    
    def _migrate_articles(self, source_dir):
        """è¿ç§»æ–‡ç« æ•°æ®"""
        articles_file = os.path.join(source_dir, 'web_articles.json')
        if not os.path.exists(articles_file):
            print(f"âš ï¸  æ–‡ç« æ–‡ä»¶ä¸å­˜åœ¨: {articles_file}")
            return
        
        print("ğŸ“¥ è¿ç§»æ–‡ç« æ•°æ®...")
        
        try:
            with open(articles_file, 'r', encoding='utf-8') as f:
                articles_data = json.load(f)
            
            for article_data in articles_data:
                try:
                    # æŸ¥æ‰¾ä½œè€…
                    author = User.query.filter_by(username=article_data['author']).first()
                    if not author:
                        print(f"âš ï¸  æ‰¾ä¸åˆ°ä½œè€…: {article_data['author']}")
                        self.stats['articles']['errors'] += 1
                        continue
                    
                    # æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å­˜åœ¨
                    existing_article = Article.query.filter_by(title=article_data['title']).first()
                    if existing_article:
                        self.stats['articles']['skipped'] += 1
                        continue
                    
                    # åˆ›å»ºæ–‡ç« 
                    article = Article(
                        title=article_data['title'],
                        content=article_data['content'],
                        author_id=author.id
                    )
                    
                    # è®¾ç½®å…¶ä»–å±æ€§
                    article.is_published = article_data.get('is_published', False)
                    article.views = article_data.get('views', 0)
                    article.likes = article_data.get('likes', 0)
                    
                    if 'created_at' in article_data:
                        article.created_at = datetime.fromisoformat(article_data['created_at'])
                    if 'updated_at' in article_data:
                        article.updated_at = datetime.fromisoformat(article_data['updated_at'])
                    
                    db.session.add(article)
                    db.session.flush()  # è·å–æ–‡ç« ID
                    
                    # å¤„ç†æ ‡ç­¾
                    if 'tags' in article_data:
                        for tag_name in article_data['tags']:
                            tag = Tag.query.filter_by(name=tag_name).first()
                            if not tag:
                                tag = Tag(name=tag_name)
                                db.session.add(tag)
                                self.stats['tags']['migrated'] += 1
                            
                            if tag not in article.tags:
                                article.tags.append(tag)
                                tag.usage_count += 1
                    
                    # å¤„ç†è¯„è®º
                    if 'comments' in article_data:
                        for comment_data in article_data['comments']:
                            try:
                                # æŸ¥æ‰¾è¯„è®ºä½œè€…
                                comment_author = User.query.filter_by(username=comment_data['author']).first()
                                if not comment_author:
                                    print(f"âš ï¸  æ‰¾ä¸åˆ°è¯„è®ºä½œè€…: {comment_data['author']}")
                                    continue
                                
                                comment = Comment(
                                    content=comment_data['content'],
                                    article_id=article.id,
                                    author_id=comment_author.id
                                )
                                
                                if 'created_at' in comment_data:
                                    comment.created_at = datetime.fromisoformat(comment_data['created_at'])
                                if 'is_approved' in comment_data:
                                    comment.is_approved = comment_data['is_approved']
                                
                                db.session.add(comment)
                                self.stats['comments']['migrated'] += 1
                                
                            except Exception as e:
                                print(f"âŒ è¿ç§»è¯„è®ºå¤±è´¥: {e}")
                                self.stats['comments']['errors'] += 1
                    
                    self.stats['articles']['migrated'] += 1
                    
                except Exception as e:
                    print(f"âŒ è¿ç§»æ–‡ç« å¤±è´¥ {article_data.get('title', 'Unknown')}: {e}")
                    self.stats['articles']['errors'] += 1
            
            db.session.commit()
            print(f"âœ… æ–‡ç« è¿ç§»å®Œæˆ: {self.stats['articles']['migrated']} ç¯‡")
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ç« æ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_migration_stats(self):
        """æ‰“å°è¿ç§»ç»Ÿè®¡"""
        print("\nğŸ“Š è¿ç§»ç»Ÿè®¡:")
        for entity_type, stats in self.stats.items():
            total = stats['migrated'] + stats['skipped'] + stats['errors']
            if total > 0:
                print(f"   {entity_type}: {stats['migrated']} è¿ç§», {stats['skipped']} è·³è¿‡, {stats['errors']} é”™è¯¯")
        
        print("\nâœ… æ•°æ®è¿ç§»å®Œæˆ!")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®è¿ç§»å·¥å…·')
    parser.add_argument('--from-files', action='store_true', help='ä»æ–‡ä»¶å­˜å‚¨è¿ç§»')
    parser.add_argument('--source-dir', default='../step4_web/data', help='æºæ•°æ®ç›®å½•')
    parser.add_argument('--config', default='development', help='é…ç½®ç¯å¢ƒ')
    
    args = parser.parse_args()
    
    if not args.from_files:
        print("è¯·æŒ‡å®šè¿ç§»ç±»å‹ï¼Œä¾‹å¦‚: --from-files")
        return
    
    # åˆ›å»ºåº”ç”¨
    app = create_app(args.config)
    
    # åˆ›å»ºè¿ç§»å™¨
    migrator = DataMigrator(app)
    
    # æ‰§è¡Œè¿ç§»
    if args.from_files:
        migrator.migrate_from_files(args.source_dir)

if __name__ == '__main__':
    main()
